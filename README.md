# Are Transformers really the best choice for Long Time Series Forecasting ? What about FreTS ?

Project realized for the *Statistical Learning* course of the Master Degree in Data Science at *Sapienza University of Rome*.   

In our project we want to compare the performance of various models, from the simplest to the most advanced, to conduct Long Time Series Forecasting. Moreover, we want to replicate the results and undesrtand a model, **FreTS**, proposed at **NeurIPS-2023** which is the state of the art for time series forecasting.

We want to answer the following questions:

- How well are Transformers able to solve TSF ? What are their weaknesses ?
- How is their performance compared to that achieved by simpler models?
- How can we intepret FreTS and can we replicate the results ?

<div align="center">
    <img src="https://github.com/bergio13/LTSF_Transformers_FreTS/blob/main/plots/Exhange-1-frets.png" style="width: 50%;" alt="FreTS Forecast - Exchange 1" />
</div>

<div align="center">
    <img src="https://github.com/bergio13/LTSF_Transformers_FreTS/blob/main/plots/Exchange-1.png" style="width: 50%;" alt="Other models Forecasts - Exchange 1" />
</div>

## Acknowledgments

The main papers we consider for our project are the following:
- FreTS: https://neurips.cc/virtual/2023/poster/70726
- Transformers effectivness in LTSF: https://arxiv.org/abs/2205.13504
  
Additionally, some code is taken from:
- FreTS: https://github.com/aikunyi/FreTS

## Group Members
- https://github.com/bergio13
- https://github.com/gianluca-24
- https://github.com/Himel1996
- https://github.com/parlanti
